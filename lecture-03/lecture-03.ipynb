{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Softmax and Cross-Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    x -= np.max(x)\n",
    "    \n",
    "    return np.exp(x) / np.sum(np.exp(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.24232893, 0.72799634, 0.02967474])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax([1.3, 2.4, -0.8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy(label, s):\n",
    "\treturn -sum([label[i]*np.log(s[i]) for i in range(len(label))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "L = [0.10, 0.40, 0.50]\n",
    "S = [0.80, 0.15, 0.05]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.279028485862769"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_entropy(L, S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "L2 = [0.5, 0.4, 0.1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.1699929969668565"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_entropy(L2, S)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 如果是一个5分类问题，那么当loss大于多少的时候，才能证明这个模型是“学习了的”？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6931471805599453"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L = [1, 0]\n",
    "S = [0.5, 0.5]\n",
    "\n",
    "cross_entropy(L, S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.3862943611198906"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L = [1, 0, 0, 0, 0]\n",
    "S = [0.25, 0.25, 0.25, 0.25, 0.25]\n",
    "\n",
    "cross_entropy(L, S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "L = [1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "S = [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.3025850929940455"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_entropy(L, S)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One-Hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities = [\n",
    "    '北京',\n",
    "    '南京',\n",
    "    '大连',\n",
    "    '青岛',\n",
    "    '上海',\n",
    "    '深圳',\n",
    "    '杭州'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "person1 = ['北京', 23]\n",
    "person2 = ['南京', 24]\n",
    "person3 = ['北京', 24]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encoder(features):\n",
    "    onehot_encoder = defaultdict(lambda : [0] * len(set(features)))\n",
    "    \n",
    "    for i, f in enumerate(set(features)):\n",
    "        onehot_encoder[f][i] = 1\n",
    "        \n",
    "    return onehot_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<function __main__.one_hot_encoder.<locals>.<lambda>()>,\n",
       "            {'深圳': [1, 0, 0, 0, 0, 0, 0],\n",
       "             '上海': [0, 1, 0, 0, 0, 0, 0],\n",
       "             '北京': [0, 0, 1, 0, 0, 0, 0],\n",
       "             '青岛': [0, 0, 0, 1, 0, 0, 0],\n",
       "             '杭州': [0, 0, 0, 0, 1, 0, 0],\n",
       "             '南京': [0, 0, 0, 0, 0, 1, 0],\n",
       "             '大连': [0, 0, 0, 0, 0, 0, 1]})"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_encoder(cities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_decoder(x, decoder):\n",
    "    v = []\n",
    "    \n",
    "    for i in x:\n",
    "        if i in decoder: v += decoder[i]\n",
    "        else:\n",
    "            v.append(i)\n",
    "        \n",
    "    return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 1, 0, 0, 0, 0, 23]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_decoder(person1, one_hot_encoder(cities))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0, 0, 1, 0, 24]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_decoder(person2, one_hot_encoder(cities))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 1, 0, 0, 0, 0, 24]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_decoder(person3, one_hot_encoder(cities))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = OneHotEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneHotEncoder(categorical_features=None, categories=None,\n",
       "       dtype=<class 'numpy.float64'>, handle_unknown='error',\n",
       "       n_values=None, sparse=True)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc.fit([[c] for c in cities])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0., 0.]])"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc.transform([['北京'], ['南京'], ['大连']]).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalizationi and Standarlized "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html\n",
    "#https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html#sklearn.preprocessing.MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "## normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "before processing\n",
      "[[111212131], [32313111], [32431131], [34353311]]\n",
      "\n",
      "after normalized\n",
      "[[1.        ]\n",
      " [0.        ]\n",
      " [0.00149584]\n",
      " [0.02585837]]\n",
      "\n",
      "after standarlized\n",
      "[[ 1.73155534]\n",
      " [-0.59843008]\n",
      " [-0.59494481]\n",
      " [-0.53818046]]\n"
     ]
    }
   ],
   "source": [
    "incomes = [[111212131], [32313111], [32431131], [34353311]]\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "normal = MinMaxScaler()\n",
    "scalar = StandardScaler()\n",
    "\n",
    "print('\\nbefore processing')\n",
    "print(incomes)\n",
    "normal.fit(incomes)\n",
    "incomes = normal.transform(incomes)\n",
    "\n",
    "print('\\nafter normalized')\n",
    "print(incomes)\n",
    "\n",
    "scalar.fit(incomes)\n",
    "\n",
    "incomes_after_processed = scalar.transform(incomes)\n",
    "\n",
    "print('\\nafter standarlized')\n",
    "print(incomes_after_processed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "before processing\n",
      "[[111212131, -123141], [32313111, -123141], [32431131, -4534642], [34353311, -3252342]]\n",
      "\n",
      "after normalized\n",
      "[[111212131, -123141], [32313111, -123141], [32431131, -4534642], [34353311, -3252342]]\n",
      "\n",
      "after standarlized\n",
      "[[ 1.73155534  0.97227959]\n",
      " [-0.59843008  0.97227959]\n",
      " [-0.59494481 -1.30295282]\n",
      " [-0.53818046 -0.64160637]]\n"
     ]
    }
   ],
   "source": [
    "incomes_with_debt = [[111212131, -123141], [32313111, -123141], [32431131, -4534642], [34353311, -3252342]]\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "normal = MinMaxScaler()\n",
    "scalar = StandardScaler()\n",
    "\n",
    "print('\\nbefore processing')\n",
    "print(incomes_with_debt)\n",
    "normal.fit(incomes_with_debt)\n",
    "incomes = normal.transform(incomes_with_debt)\n",
    "\n",
    "print('\\nafter normalized')\n",
    "print(incomes_with_debt)\n",
    "\n",
    "scalar.fit(incomes_with_debt)\n",
    "\n",
    "incomes_after_processed = scalar.transform(incomes_with_debt)\n",
    "\n",
    "print('\\nafter standarlized')\n",
    "print(incomes_after_processed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
